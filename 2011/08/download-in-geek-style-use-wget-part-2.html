
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Download in Geek Style: Use Wget (Part 2) - Beat of The Geek</title>
  <meta name="author" content="Charanjit Singh">

  
  <meta name="description" content="Hello there ! !After our last article on Introduction to wget for Linux newbies, it is time to advance a little further. In this article &nbsp;we&# &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://\.github.io/\/github/2011/08/download-in-geek-style-use-wget-part-2.html">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="http://feeds.feedburner.com/beatofthegeek" rel="alternate" title="Beat of The Geek" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=Raleway:100" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=Lora:400,400italic,700,700italic|Istok+Web:400,400italic,700,700italic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-46660370-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
  <div id="header-container">
    <div id="header">
      <div class="wrapper">
        <header role="banner"><hgroup>
  <h1><a href="/">Beat of The Geek</a></h1>
</hgroup>

</header>
        <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="http://feeds.feedburner.com/beatofthegeek" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:\.github.io/\/github" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
      </div>
    </div>
  </div>
  <div id="body"   >
    <div id="main">
      <div id="content">
	<div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Download in Geek Style: Use Wget (Part 2)</h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-08-21T00:00:00+05:30" pubdate data-updated="true">Aug 21<span>st</span>, 2011</time>
        
         | <a href="#disqus_thread">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><div class='post'>
<div dir="ltr" style="text-align: left;" trbidi="on">Hello there ! !<br />After our last <a href="http://channikhabra.blogspot.com/2011/08/download-in-geek-style-use-wget-part-1.html">article on Introduction to wget for Linux newbies</a>, it is time to advance a little further. In this article &nbsp;we&#8217;ll discuss advanced usage of Wget.<br />Let&#8217;s start with Wget&#8217;s most wanted command:<br /><br /><span class="Apple-style-span" style="font-size: 19px; font-weight: bold;"><b><span class="Apple-style-span" style="color: #6aa84f; font-size: small;"></span></b></span><br /><b><span class="Apple-style-span" style="color: #6aa84f;">Downloading Recursively (-r switch)</span></b><br /><div><span class="Apple-style-span" style="color: #6aa84f;"><b><br /></b></span>Wget can download recursively, following all the links it meet in the way of downloading process. For example, you are reading an online book (ebook of course), which has links to further chapters. Using this command you can easily download all the pages of the ebook with a single command making your own copy of the ebook to be read offline. Even better, doing some Google we can download as many mp3s or other files as we want, all in a single command.<br />Excited ? (I know you are)<br />All right, enough talking.<br /><span class="Apple-style-span" style="color: #6aa84f; font-weight: bold;"></span><br /><hr /><br /><!-- more --><br /><br /><span class="Apple-style-span" style="color: #6aa84f; font-weight: bold;"><span class="Apple-style-span" style="font-size: large;">How to download recursively</span></span><br /><br /><code> wget -r -l 7 --no-parent&nbsp;</code><span class="Apple-style-span" style="font-family: monospace;">-A pdf,djvu&nbsp;</span><span class="Apple-style-span" style="font-family: monospace;">-nH &#8211;cut-dirs=4 -P &#8220;My download directory&#8221; &#8220;Link to download page&#8221;&nbsp;</span><br />&nbsp;<b>Time for some explanations:</b><br /><b><span class="Apple-style-span" style="color: #6aa84f;">-r or &#8211;recursive</span>&nbsp; &nbsp;</b>This switch tell wget to start downloading recursively from the link given.<br /><br /><b><span class="Apple-style-span" style="color: #6aa84f;">-l or &#8211;level=&#8217;depth&#8217;</span></b> &nbsp; &nbsp;When downloading recursively, wget follows a system of levels. This denotes the levels of depth to which wget will follow links.<br />As in above example when we start a download from page 1 with level stated to be 7, wget download main page first. After this it follows all the links given on the page. This is level one. After downloading everything, wget starts following links given in downloaded pages. This is level 2. Similarly wget will download everything &nbsp;following every link it meet in the way until it reaches maximum depth.<br />By default, wget sets depth level to be 5. It can also be set to infinite<br /><blockquote><code>wget -r -l inf "download link" </code> or <code>wget -r l 0 "link"</code></blockquote><br /><span class="Apple-style-span" style="color: #6aa84f;"><b>&#8211;no-parent or -np </b></span>&nbsp; Wget&#8217;s recursive download is bidirectional. It means wget follows link in both directions of link&nbsp;hierarchy (err&#8230; what is that?).<br />Let&#8217;s see an example. Assume we are downloading free ebooks from a website, say example.com/ebooks/english/list.html . So&nbsp;&nbsp;what we want is downloading English books only. But by default, wget will follow all links on list.html BUT it will also move upwards and follow links it find there. This is not what we want.<br />SO here is &#8211;no-parent. It is a very useful command which ensures that we download only downwards the hierarchy and don&#8217;t go upwards. <br /><br /><span class="Apple-style-span" style="color: #6aa84f;"><b>Download specific file types (-A &#8216;filetype or list&#8217; or &#8211;accept=&#8221;list of filetypes&#8221;)</b></span> &nbsp; &nbsp;When downloading ebooks from our kind website, we don&#8217;t want any HTML,CSS or Javascript files to be downloaded. By default, wget will download everything including images, scripts &nbsp;and everything. -A or &#8211;accept switch allow us to download only desired files. In the example, we want only .pdf and .djvu files to be downloaded, and wget will do that, strictly following our orders. Multiple filetypes can be given separated by commas.<br /><br /><span class="Apple-style-span" style="color: #6aa84f;"><b>-R &#8220;list of filetypes&#8221; or &#8211;reject=&#8221;filetypes&#8221;</b></span> &nbsp; Similar to -A is -R. While -A accepts some files and rejects others -R, rejects some given filetypes and download everything else.<br /><br /><span class="Apple-style-span" style="color: #6aa84f;"><b><u>Handling Directories</u></b></span><br /><br /><span class="Apple-style-span" style="color: #6aa84f;"><b>-P &#8220;path&#8221; or &#8211;directory-prefix=&#8221;path&#8221; </b></span>&nbsp; As stated in <a href="http://channikhabra.blogspot.com/2011/08/download-in-geek-style-use-wget-part-1.html">previous article</a>, -P can be used to redirect downloaded file to some specific path.<br /><br />But when downloading recursively, there is one problem. Wget saves all the files in the same directory hierarchy as they were on the server. As in our example, by default all files will be saved as this,<br /><blockquote>&nbsp;Home Folder&gt; example.com &gt; ebooks &gt; english&gt; file.pdf</blockquote>This behavior can be very irritating for normal users like us. But no worries, wget provides many options to handle this our own way. Here are some most commonly used ones.<br /><br /><span class="Apple-style-span" style="color: #6aa84f;"><b>&#8211;cut-dirs=x </b></span>&nbsp; &nbsp;This is useful command for controlling the directory structure of the location where recursively downloaded files will be saved. It cut the &#8220;x&#8221; directory components from the hierarchy.<br /><br /><span class="Apple-style-span" style="color: #6aa84f;"><b>&#8211;nH or &#8211;no-host-directories</b></span> &nbsp; &nbsp;This command cuts the name of host from directory structure. In other words, it disables generation of host prefixed directories.<br /><br /><span class="Apple-style-span" style="color: #6aa84f;"><b>-nd or &#8211;no-directories</b></span> &nbsp; It suggests wget to not to use any directory structure at all and save all the files in open (by default) or in the folder specified by -P command.<br /><br /><b>Example:</b><br />Assume that we are recursively downloading (pdf) files from example.com/ebooks/english, then this is how they will be saved on our PC with different commands&#8230;<br /><br /><blockquote>No options &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;-&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;example.com/ebooks/english/file.pdf<br />-nH &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; -&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;ebooks/english/file.pdf<br />-nH &#8211;cut-dirs=1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;-&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;english/file.pdf<br />&#8211;cut-dirs=1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; -&gt; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;example.com/english/file.pdf</blockquote>Got it ?&#8230;.Good&#8230; : )<br /><br /><span class="Apple-style-span" style="color: #6aa84f;"><b>Making readable Offline Copies of Websites</b></span><br /><span class="Apple-style-span" style="color: #6aa84f;"><b><br /></b></span>It is really easy to make offline copies of websites, just start a recursive download and it is done. No it is not.<br />&nbsp;Think of the links given on pages. For example, if we download an ebook (HTML files) which has links to next chapters and other such links, all of them point to pages available on server, like &nbsp;an ebook at &#8220;example.com/onlinebook/contents&#8221; will have link to chapter 1 like this, &#8220;example.com/onlinebook/chapter1&#8221;. Even in an offline copy (that we have made using wget), clicking on this link will take us online to the server. But this is not what we want.<br /><div>Again, no worries, wget has a solution for this.</div><div><br /></div><div><span class="Apple-style-span" style="color: #6aa84f;"><b>-k or &#8211;convert-links</b></span>&nbsp; &nbsp; This is an extremely useful option which converts all the links in downloaded pages to their local copies (if they are downloaded). In case HTML files have link to the content which has not been downloaded, wget will convert those links to their absolute location (internet of course). This ensures that there are no broken links and make local viewing smooth.</div><div><br /></div><div><span class="Apple-style-span" style="color: #6aa84f;"><b>-p or &#8211;page-requisites </b></span>&nbsp; &nbsp; As all other wget commands, this is also a very useful command which help to download all the files which are necessary for proper display of a page. It downloads everything (images, sounds, style sheet references etc) which are necessary for proper display of page even if they are located on different websites.<br /><br /><b><span class="Apple-style-span" style="color: #6aa84f; font-size: large;">When She said NO !!</span></b><br /><br />Sometimes web servers don&#8217;t allow tools like wget to access &nbsp;their data and hence we can&#8217;t download from such servers. But as I am saying from very&nbsp;<a href="http://channikhabra.blogspot.com/2011/08/download-in-geek-style-use-wget-part-1.html">beginning</a>, wget has a way for everything (almost). Here are some useful commands which can be used to get access when the server says no and tempt to kick your ass.<br /><br /><span class="Apple-style-span" style="color: #6aa84f;"><b>-U &#8220;agent&#8221; or &#8211;user-agent=&#8221;agent&#8221; </b></span>&nbsp; &nbsp;When wget access a file on a HTTP server, it identifies itself by sending a user agent string (header field). It is like it says to server, &#8220;Hey baby, this is wget. Wassup ?&#8221;. But sometimes HTTP servers deny connections to some agents (web browser, wget etc are all agents which allow us access Internet through protocols) or only allow some specific agents to access their data. We can fool the server by changing the user agent string. The command looks like this:<br /><blockquote><code>wget -U "Mozilla/5.0"</code>&nbsp;or&nbsp;<code>wget --user-agent="Mozilla/5.0"</code></blockquote>Here Mozilla is name of agent and 5.0 is version number. What we are doing is, changing user ID to look as if it was sent by your browser or at least hide the fact that it is sent by wget.<br />Actual User ID string is &nbsp;pretty long and carry more information, but this much is fine for fooling most web servers. We can also say wget to not to send any user ID with this command:<br /><blockquote><code>wget --user-agent=""</code>&nbsp; &nbsp;</blockquote><span class="Apple-style-span" style="color: #6aa84f;"><b>&#8211;referer=url </b></span>&nbsp; &nbsp;This command includes the &#8220;Referer: url&#8221; in the HTTP request. Sometimes servers expect that their data is always accessed by web browsers which are always sent by some page which points to them. This command is not used often, but may be useful in some particular case.<br /><br /><span class="Apple-style-span" style="color: #6aa84f;"><b>&#8211;http-user=user and &#8211;http-password=password</b></span> &nbsp; In case you have an account on the server and server needs username and password to authenticate the request, these commands are to be used. Similar commands are <b>&#8211;ftp-user=user</b> and <b>&#8211;ftp-password=password</b> for ftp servers and <b>&#8211;user=user</b> and <b>&#8211;password=password</b> for both http and ftp servers. Latter two have lower preference than first two command sets.<br /><br /><span class="Apple-style-span" style="color: #6aa84f;"><b>-w seconds or &#8211;wait=seconds </b></span>&nbsp; &nbsp; This command wait for given number of seconds between two consecutive downloads thus decreasing the load on the server. Instead of in seconds, time can be given in minutes with &#8220;m&#8221; suffix or in hours or even in days with &#8220;h&#8221; and &#8220;d&#8221; suffices. Large values can be useful in case destination server is down, giving wget enough time to retry and wait till it is up again.<br /><br /><span class="Apple-style-span" style="color: #6aa84f;"><b>&#8211;random-wait </b></span>&nbsp; Sometimes, web servers do analyse the traffic coming to them and find out if automatic tools like wget access them. They usually count the time between requests they&nbsp;receive&nbsp;and deny further requests, &#8211;random-wait switch allows us to make wget wait for random time between&nbsp;consecutive&nbsp;downloads and fooling the server.<br />This option causes the&nbsp;time between requests to vary between 0.5 and 1.5 * wait seconds,where wait was specified using the &#8211;wait option, in order to mask&nbsp;Wget&#8217;s presence from such analysis.<br /><div><br /></div><div><span class="Apple-style-span" style="color: #6aa84f;"><b>Unleash the power of Google</b></span><br /><span class="Apple-style-span" style="color: #6aa84f;"><b><br /></b></span></div>Google too has a syntax like *nix commands, which can be used for finding desired results from over billions of pages on Internet. We can get just what we want if we use it smartly. Here we want a pure list of downloadable files, which we can download with wget. Just enter this string in Google Search Bar and hit enter:</div><div><blockquote><i>intitle:&#8221;index of/&#8221; mp3 &#8220;your favorite band&#8221; parent directory</i></blockquote>This will give links to pages which only have links to mp3 files of your favorite band ready to download. This link can be passed to wget for a recursive download with required recursion depth to&nbsp;successfully&nbsp;get what we want. Tinker with above search string to get other kind of stuff, may be videos, ebooks or whatever.<br />(This is meant for educational purposes only. Downloading this way is not legal. Use at your own risk&#8230; :P)<br /><br />Wget has much more than this. Refer to wget manual pages for more advanced and&nbsp;insight&nbsp;information.<br />HAPPY HACKING&#8230; :D<br /><br /><hr style="text-align: justify;" /><div style="text-align: justify;"><br /></div><div style="text-align: justify;"><b><i>Circle Beat Of The Geek on</i></b>&nbsp;<a href="https://plus.google.com/109838896781876000861" target="_blank">Google Plus</a></div><div style="text-align: justify;"><i><b>OR Like us on</b></i>&nbsp;<a href="https://www.facebook.com/pages/Beat-Of-The-Geek/251813454834549" target="_blank">Facebook</a>&nbsp;<b><i>&nbsp;OR Follow on</i></b>&nbsp;<a href="https://twitter.com/#!/beatofthegeek" target="_blank">Twitter</a></div></div></div></div></div>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Charanjit Singh</span></span>

      








  


<time datetime="2011-08-21T00:00:00+05:30" pubdate data-updated="true">Aug 21<span>st</span>, 2011</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/debian/'>Debian</a>, <a class='category' href='/blog/categories/gnu-slash-linux/'>GNU/Linux</a>, <a class='category' href='/blog/categories/linux-beginners/'>Linux Beginners</a>, <a class='category' href='/blog/categories/mint/'>Mint</a>, <a class='category' href='/blog/categories/ubuntu/'>Ubuntu</a>, <a class='category' href='/blog/categories/wget/'>wget</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/2011/08/download-in-geek-style-use-wget-part-1.html" title="Previous Post: Download in Geek Style: Use Wget (Part 1)">&laquo; Download in Geek Style: Use Wget (Part 1)</a>
      
      
        <a class="basic-alignment right" href="/2011/08/finetune-ui-with-mouse-gestures.html" title="Next Post: Finetune Ui With Mouse Gestures">Finetune Ui With Mouse Gestures &raquo;</a>
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/2014/10/quickies-and-loud-mouth.html">`quickie` and `loud mouth`</a>
      </li>
    
      <li class="post">
        <a href="/2014/10/how-to-find-which-application-is-running-on-a-particular-port.html">Find which application is running on a particular port</a>
      </li>
    
      <li class="post">
        <a href="/2014/02/the-awesome-of-web-browsing-with-emacs.html">The awesome of web browsing with Emacs</a>
      </li>
    
      <li class="post">
        <a href="/2014/02/my-setup-for-using-emacs-as-web-browser.html"> My setup for using Emacs as web browser</a>
      </li>
    
      <li class="post">
        <a href="/2014/02/some-tips-for-developing-firefox.html">Some tips for developing Firefox Extensions in Emacs</a>
      </li>
    
      <li class="post">
        <a href="/2014/02/differnet-ways-of-accessing-commit-in.html">Differnet ways of accessing a commit in git</a>
      </li>
    
      <li class="post">
        <a href="/2014/01/linux-boot-process-real-quick-walkthrough.html">"To know me better, try walk in my boots", said GNU/Linux</a>
      </li>
    
      <li class="post">
        <a href="/2014/01/git-commit-illustrated-simplicity.html">git commit illustrated: Simplicity revealed by a complex exercise for simplest git task</a>
      </li>
    
      <li class="post">
        <a href="/2014/01/5-cool-things-to-do-with-netcat.html">5 cool things to do with `netcat'</a>
      </li>
    
      <li class="post">
        <a href="/2014/01/5-things-i-frequently-do-and-forget.html">5 things I frequently do and forget with git</a>
      </li>
    
  </ul>
</section>

  
</aside>


      </div>
    </div>
    <footer role="contentinfo"><p>
  Copyright &copy; 2014 - Charanjit Singh -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a>. Design by <a href="http://octopressthemes.com">Octopress Themes</a>.</span>
</p>

</footer>
    

<script type="text/javascript">
      var disqus_shortname = 'beatofthegeek';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://\.github.io/\/github/2011/08/download-in-geek-style-use-wget-part-2.html';
        var disqus_url = 'http://\.github.io/\/github/2011/08/download-in-geek-style-use-wget-part-2.html';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>











  </div>
</body>
</html>
